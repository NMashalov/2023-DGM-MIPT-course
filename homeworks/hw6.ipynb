{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZXJoDiD_x-N"
   },
   "source": [
    "# Homework6: Denoising Diffusion generative models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxF8ewFXn1HO"
   },
   "source": [
    "## Task 1: Theory (4pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFn6d3vkuZIl"
   },
   "source": [
    "### Problem 1: KFP theorem (2pt)\n",
    "\n",
    "In Lecture 10 we have faced with 2 different formulations of Kolmogorov-Fokker-Planck theorem.\n",
    "\n",
    "1) We used the following KFP theorem when we discussed continuous-in-time NF:\n",
    "$$\n",
    "\\frac{d \\log p(\\mathbf{x}(t), t)}{d t} = - \\text{tr} \\left( \\frac{\\partial f(\\mathbf{x}, t)}{\\partial \\mathbf{x}} \\right).\n",
    "$$\n",
    "\n",
    "2) We used the following KFP theorem when we discussed SDEs:\n",
    "$$\n",
    "\\frac{\\partial p(\\mathbf{x}, t)}{\\partial t} = \\text{tr}\\left(- \\frac{\\partial}{\\partial \\mathbf{x}} \\bigl[ \\mathbf{f}(\\mathbf{x}, t) p(\\mathbf{x}, t)\\bigr] + \\frac{1}{2} g^2(t) \\frac{\\partial^2 p(\\mathbf{x}, t)}{\\partial \\mathbf{x}^2} \\right)\n",
    "$$\n",
    "\n",
    "In this task your goal is to prove that the first formulation is a special case of the more general second formulation.\n",
    "\n",
    "You have to use two facts:\n",
    "1) Continuous-in-time NF use ODE (not SDE).\n",
    "2) The derivation in the first formulation is total derivative (not partial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbxPyzwcuinj"
   },
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5rbPI8f0ZFy"
   },
   "source": [
    "### Problem 2: Faster sampling with DDPM (spaced diffusion) (2pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWkz0w2_haMk"
   },
   "source": [
    "Sampling from DDPM is very slow. In the practical part of HW you will see that it took about 8 seconds to generate a batch of images with our diffusion model (even using a gpu).\n",
    "While, as you might remember, it took less than a second using other generative models (VAE/GAN/NF).\n",
    "This drawback can't be solved generally with using more gpus, since it requires iterative sampling.\n",
    "There are several techniques to alleviate this drawback. In this task We are going to investigate one of them.\n",
    "\n",
    "Assume we have already trained a model $p(\\mathbf{x}_{t - 1} | \\mathbf{x}_t, \\boldsymbol{\\theta})$ to \"reverse\" a Markov chain of length $T$.\n",
    "\n",
    "Let try to build inference process using subsequence of timesteps\n",
    "$\\{S_0 = 0, S_1, \\ldots, S_{T'-1}, S_{T'} = T\\}$, where $T' < T$.\n",
    "\n",
    "Using this subsequence we have to do $T' (< T)$ inference steps instead of $T$. It could dramatically reduce inference time.\n",
    "\n",
    "Diffusion models inference are essentially defined by\n",
    "- schedule of variances $\\{\\beta_1, \\ldots, \\beta_T\\}$\n",
    "- reverse process:\n",
    "$$\n",
    "p(\\mathbf{x}_{S_{t - 1}} | \\mathbf{x}_{S_t}, \\boldsymbol{\\theta}) = \\mathcal{N} \\bigl(\\mathbf{x}_{S_{t - 1}} | \\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{x}_{S_t}, S_t), \\tilde{\\beta}_{S_t}\\bigr)\n",
    "$$\n",
    "\n",
    "Therefore, all you have to find is the variances for the new Markov chain: $\\{\\tilde{\\beta}_{S_1}, \\ldots, \\tilde{\\beta}_{S_{T'}}\\}$.\n",
    "\n",
    "**Task:** find the expression for $\\tilde{\\beta}_{S_t}$ (it should depend on $\\alpha$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVsqN1O3uk6x"
   },
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41370,
     "status": "ok",
     "timestamp": 1700068971438,
     "user": {
      "displayName": "Роман Исаченко",
      "userId": "08996523319375397632"
     },
     "user_tz": -180
    },
    "id": "nYZ__zsi3McN",
    "outputId": "1153bb7c-f9cd-4a0f-83bd-e2827f989f53"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --no-cache-dir gdown\n",
    "\n",
    "REPO_NAME = \"2023-DGM-MIPT-course\"\n",
    "!if [ -d {REPO_NAME} ]; then rm -Rf {REPO_NAME}; fi\n",
    "!git clone https://github.com/r-isachenko/{REPO_NAME}.git\n",
    "!cd {REPO_NAME}\n",
    "!pip install ./{REPO_NAME}/homeworks/\n",
    "!mv ./{REPO_NAME}/homeworks/unet.py ./unet.py\n",
    "!rm -Rf {REPO_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5371,
     "status": "ok",
     "timestamp": 1700068976805,
     "user": {
      "displayName": "Роман Исаченко",
      "userId": "08996523319375397632"
     },
     "user_tz": -180
    },
    "id": "7mC57wAo5Yag"
   },
   "outputs": [],
   "source": [
    "from dgm_utils import visualize_2d_data, visualize_2d_samples, visualize_images, show_samples, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1112,
     "status": "ok",
     "timestamp": 1700068977911,
     "user": {
      "displayName": "Роман Исаченко",
      "userId": "08996523319375397632"
     },
     "user_tz": -180
    },
    "id": "grmP96FjfQZg"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRFti0_GCRpD"
   },
   "source": [
    "## Task 2: DDPM for 2D data (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8vx6pxgCqBv"
   },
   "source": [
    "In this part you have to implement your own diffusion model (DDPM) and apply it to 2D dataset.\n",
    "\n",
    "Let's take a look at dataset samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_moons_data(count: int) -> tuple:\n",
    "    data, labels = make_moons(n_samples=count, noise=0.1)\n",
    "    data = data.astype(\"float32\")\n",
    "    split = int(0.8 * count)\n",
    "    train_data, test_data = data[:split], data[split:]\n",
    "    train_labels, test_labels = labels[:split], labels[split:]\n",
    "    return train_data, train_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = 5000\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = generate_moons_data(COUNT)\n",
    "visualize_2d_data(train_data, test_data, train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRqWAIRmQDQ8"
   },
   "source": [
    "Below you see the utility function, which broadcasts tensors. Look carefully at this code, we will use it in the majority of methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1700071356289,
     "user": {
      "displayName": "Роман Исаченко",
      "userId": "08996523319375397632"
     },
     "user_tz": -180
    },
    "id": "0VwXNzi6fQZm"
   },
   "outputs": [],
   "source": [
    "def _extract_into_tensor(arr, indices, broadcast_shape):\n",
    "    \"\"\"\n",
    "    Extract values from a 1-D torch tensor for a batch of indices.\n",
    "    :param arr: 1-D torch tensor.\n",
    "    :param timesteps: a tensor of indices to extract from arr.\n",
    "    :param broadcast_shape: a larger shape of K dimensions with the batch\n",
    "                            dimension equal to the length of timesteps.\n",
    "    :return: a tensor of shape [batch_size, 1, ...] where the shape has K dims.\n",
    "    \"\"\"\n",
    "    assert len(arr.shape) == 1\n",
    "    res = arr.to(device=indices.device)[indices].float()\n",
    "    while len(res.shape) < len(broadcast_shape):\n",
    "        res = res[..., None]\n",
    "\n",
    "\n",
    "    return res.expand(broadcast_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Diffusion\n",
    "\n",
    "Let start with forward diffusion.\n",
    "\n",
    "**Forward process** is defined as a posterior distribution $q(\\mathbf{x}_{1:T}|\\mathbf{x}_0)$.\n",
    "\n",
    "It is a Markov chain, which consequently adds gaussian noise to a given object $\\mathbf{x}_0$.\n",
    "\n",
    "At every step of this process the gaussian noise is added with different magnitude, which is determined with a schedule of variances $\\{\\beta_1, ... \\beta_T\\}$.\n",
    "If this schedule is chosen properly and T goes to infinity (or is large enough), we will converge to pure noise $\\mathcal{N}(0, I)$.\n",
    "\n",
    "Markov chain is defined by:\n",
    "$$\n",
    " q(\\mathbf{x}_t | \\mathbf{x}_{t - 1}) := \\mathcal{N}(\\mathbf{x}_t | \\sqrt{1 - \\beta_t}x_{t - 1}, \\beta_tI), \\ \\ \\ \\ \\ \\ \\ q(\\mathbf{x}_{1:T}|\\mathbf{x}_0) = \\prod_{t = 1}^T q(\\mathbf{x}_t | \\mathbf{x}_{t - 1})\n",
    "$$\n",
    "\n",
    "In order to get $\\mathbf{x}_t$ we have to compute $\\mathbf{x}_1, ..., \\mathbf{x}_{t - 1}$ iteratively.\n",
    "\n",
    "Hopefully, due to the properties of the gaussian distribution we can do it more efficiently.\n",
    "\n",
    "Let's denote\n",
    "$\\alpha_t = 1- \\beta_t$ и $\\bar{\\alpha}_t= \\prod_{s = 1}^t\\alpha_s$. \n",
    "Then\n",
    "$$\n",
    "q(\\mathbf{x}_t | \\mathbf{x}_0) = \\mathcal{N}(\\mathbf{x}_t|\\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0, (1-\\bar{\\alpha}_t) \\mathbf{I}).\n",
    "\\tag{1}\n",
    "$$\n",
    "\n",
    "Here we could get very useful expression\n",
    "$$\n",
    "    \\mathbf{x}_t = \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{1-\\bar{\\alpha}_t} \\cdot \\boldsymbol{\\epsilon}. \\tag{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create base class for diffusion (we will use it as a python base class for forward and backward diffusions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDiffusion:\n",
    "    def __init__(self, num_timesteps: int):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.betas = self._get_beta_schedule(num_timesteps)\n",
    "        self.alphas = 1 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=-1)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_beta_schedule(num_diffusion_timesteps):\n",
    "        assert num_diffusion_timesteps >= 20\n",
    "        scale = 1000 / num_diffusion_timesteps\n",
    "        beta_start = scale * 0.0001\n",
    "        beta_end = scale * 0.02\n",
    "        betas = np.linspace(beta_start, beta_end, num_diffusion_timesteps, dtype=np.float64)\n",
    "        assert len(betas.shape) == 1, \"betas must be 1-D\"\n",
    "        assert (betas > 0).all() and (betas <= 1).all()\n",
    "        betas = torch.from_numpy(betas).double()\n",
    "        return betas\n",
    "\n",
    "\n",
    "basediff = BaseDiffusion(num_timesteps=20)\n",
    "basediff.betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to define forward diffusion process. It has 2 methods: \n",
    "- to get mean and variance of the distribution $q(\\mathbf{x}_t | \\mathbf{x}_0)$,\n",
    "- to get samples from this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 805,
     "status": "ok",
     "timestamp": 1700071935422,
     "user": {
      "displayName": "Роман Исаченко",
      "userId": "08996523319375397632"
     },
     "user_tz": -180
    },
    "id": "S3X5Gm1aC3zc"
   },
   "outputs": [],
   "source": [
    "class ForwardDiffusion(BaseDiffusion):\n",
    "    def get_mean_variance(self, x0, t):\n",
    "        # ====\n",
    "        # your code\n",
    "        # calculate mean and variance of the distribution q(x_t | x_0) (use equation (1))\n",
    "        sqrt_alphas_cumprod = self.alphas_cumprod.sqrt()\n",
    "        # ====\n",
    "        return mean, variance\n",
    "\n",
    "    def get_samples(self, x0, t, noise=None):\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x0)\n",
    "        # ====\n",
    "        # your code\n",
    "        # sample from the distribution q(x_t | x_0) (use equation (2))\n",
    "        # ====\n",
    "        return samples\n",
    "\n",
    "\n",
    "def test_forward_diffusion():\n",
    "    fdiff = ForwardDiffusion(num_timesteps=100)\n",
    "    SHAPE = [2, 20]\n",
    "    x0 = torch.ones(SHAPE)\n",
    "    t = torch.ones((2,)).long() * 5\n",
    "    mean, variance = fdiff.get_mean_variance(x0=x0, t=t)\n",
    "    assert list(mean.shape) == SHAPE\n",
    "    assert list(variance.shape) == SHAPE\n",
    "    assert np.allclose(mean.numpy(), np.ones(SHAPE) * 0.9820154)\n",
    "    assert np.allclose(variance.numpy(), np.ones(SHAPE) * 0.03564582)\n",
    "\n",
    "    xt = fdiff.get_samples(x0=x0, t=t)\n",
    "    assert list(xt.shape) == SHAPE\n",
    "\n",
    "    noise = torch.ones(SHAPE)\n",
    "    xt = fdiff.get_samples(x0=x0, t=t, noise=noise)\n",
    "    assert np.allclose(xt.numpy(), np.ones(SHAPE) * 1.1708164)\n",
    "\n",
    "\n",
    "test_forward_diffusion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let visualize the forward diffusion process. Here you have to see how the distribution of the real samples transforms to the gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3hgwOcGfQZo"
   },
   "outputs": [],
   "source": [
    "T = 100\n",
    "\n",
    "fdiff = ForwardDiffusion(num_timesteps=T)\n",
    "\n",
    "timestamps=[0, 2, 4, 10, 50]\n",
    "\n",
    "plot_n_steps = len(timestamps)\n",
    "for i, t in enumerate(timestamps):\n",
    "    x = fdiff.get_samples(x0=torch.from_numpy(train_data), t=torch.ones((train_data.shape[0], 1)).long() * t)\n",
    "    visualize_2d_samples(x, title=f\"Step of diffusion: {t}\", labels=train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverse Diffusion\n",
    "\n",
    "**Reverse process** consequently denoises pure gaussian noise $\\mathcal{N}(0, \\mathbf{I})$ until we do not get the object from the original distribution $\\pi(\\mathbf{x})$.\n",
    "\n",
    "It is a probability model with latent variables\n",
    "$p(\\mathbf{x}_0 | \\boldsymbol{\\theta}) := \\int p(\\mathbf{x}_{0:T} | \\boldsymbol{\\theta}) d\\mathbf{x}_{1:T}$,\n",
    "where \n",
    "- latents $\\mathbf{z} = \\{\\mathbf{x}_1, ..., \\mathbf{x}_T \\}$ correspond to noised objects\n",
    "- $\\mathbf{x}_0$ is an object from the original distribution $\\pi(\\mathbf{x})$.\n",
    "\n",
    "Joint distribution $p(\\mathbf{x}_{0:T} | \\boldsymbol{\\theta})$ is called reverse diffusion process, which is essentially a Markov chain of gaussian distributions $p(\\mathbf{x}_{i-1}|\\mathbf{x}_{i}, \\boldsymbol{\\theta})$:\n",
    "$$\n",
    "p(\\mathbf{x}_{0:T}) = p(\\mathbf{x}_T) \\prod_{t = 1}^T p(\\mathbf{x}_{t-1}|\\mathbf{x}_t, \\boldsymbol{\\theta}), \\quad p(\\mathbf{x}_{T} | \\boldsymbol{\\theta})=\\mathcal{N}(\\mathbf{x}_T | 0, \\mathbf{I})\n",
    "$$\n",
    "$$\n",
    "  p(\\mathbf{x}_{t - 1}|\\mathbf{x}_t | \\boldsymbol{\\theta}) = \\mathcal{N}(\\mathbf{x}_{t - 1}| \\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t, t), \\boldsymbol{\\sigma}^2_{\\boldsymbol{\\theta}}(\\mathbf{x}_t, t)). \\tag{3}\n",
    "$$\n",
    "\n",
    "In Lecture 12 we have derived ELBO for this model:\n",
    "\n",
    "$$\n",
    "    \\mathcal{L}(q, \\boldsymbol{\\theta}) =  \\mathbb{E}_{q} \\Bigl[\\log p(\\mathbf{x}_0 | \\mathbf{x}_1, \\boldsymbol{\\theta}) - KL\\bigl(q(\\mathbf{x}_T | \\mathbf{x}_0) || p(\\mathbf{x}_T)\\bigr)\n",
    "    - \\sum_{t=2}^T \\underbrace{KL \\bigl(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) || p(\\mathbf{x}_{t - 1} | \\mathbf{x}_t, \\boldsymbol{\\theta} )\\bigr)}_{\\mathcal{L}_t} \\Bigr].\n",
    "$$\n",
    "\n",
    "Here we use the following distribution $q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) = \\mathcal{N}(\\mathbf{x}_{t-1}; \\boldsymbol{\\mu}(\\mathbf{x}_t, \\mathbf{x}_0), \\tilde{\\beta}_t \\mathbf{I}) $, where\n",
    "$$\n",
    "\\boldsymbol{\\mu}(\\mathbf{x}_t, \\mathbf{x}_0) = \\frac{\\sqrt{\\alpha_t}(1 - \\bar{\\alpha}_{t-1})}{1 - \\bar{\\alpha}_t} \\mathbf{x}_t + \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}\\beta_t}{1 - \\bar{\\alpha}_t} \\mathbf{x}_0\n",
    "\\tag{4}\n",
    "$$\n",
    "$$\n",
    "\\tilde{\\beta}_t = \\frac{1 - \\bar{\\alpha}_{t-1}}{1 - \\bar{\\alpha}_t} \\cdot \\beta_t\n",
    "\\tag{5}\n",
    "$$\n",
    "\n",
    "(These scary formulas are not difficult to derive, follow the link to find details [Denoising Diffusion Probabilistic Models (Ho et al. 2020)](https://arxiv.org/abs/2006.11239)).\n",
    "\n",
    "Now our goal is to define parameters $\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t, t), \\boldsymbol{\\sigma}^2_{\\boldsymbol{\\theta}}(\\mathbf{x}_t, t)$ of reverse diffusion.\n",
    "\n",
    "#### Variance\n",
    "Our first assumption is to set the variance $\\boldsymbol{\\sigma}^2_{\\boldsymbol{\\theta}}(\\mathbf{x}_t, t) = \\tilde{\\beta}_t$. This is very native assumption\n",
    "\n",
    "#### Mean\n",
    "Here we will use the expression (2) to get $\\mathbf{x}_0$ from $\\mathbf{x}_t$:\n",
    "$$\n",
    "    \\mathbf{x}_0 = \\frac{\\mathbf{x}_t - \\sqrt{1 - \\bar{\\alpha}_{t}} \\cdot \\boldsymbol{\\epsilon}}{\\sqrt{\\bar{\\alpha}_{t}}}.\n",
    "    \\tag{6}\n",
    "$$\n",
    "\n",
    "If we put this expression to the formula (4) we will get:\n",
    "$$\n",
    "    \\boldsymbol{\\mu}(\\mathbf{x}_t, \\mathbf{x}_0) = \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\cdot \\boldsymbol{\\epsilon} \\right).\n",
    "$$\n",
    "\n",
    "So the idea here to parametrize the model mean in the same functional form:\n",
    "$$\n",
    "    \\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t, t) = \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\cdot \\boldsymbol{\\epsilon}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t, t) \\right).\n",
    "$$\n",
    "\n",
    "**Note:** our model will predict the noise which was applied to $\\mathbf{x}_0$ to get $\\mathbf{x}_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseDiffusion(BaseDiffusion):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.alphas_cumprod_prev = torch.cat(\n",
    "            [torch.tensor([1.0], device=self.betas.device), self.alphas_cumprod[:-1]], dim=0\n",
    "        )\n",
    "\n",
    "        # ====\n",
    "        # your code\n",
    "        # calculate variance of the distribution q(x_{t-1} | x_t, x_0) mean (use equation (5))\n",
    "        variance = \n",
    "        # ====\n",
    "        # first value is zero, futher we will take log of this expression, so we will replace first value by the second value.\n",
    "        self.variance_clipped = torch.cat([variance[1:2], variance[1:]], dim=0)\n",
    "\n",
    "        # ====\n",
    "        # your code\n",
    "        # calculate coefficients of the distribution q(x_{t-1} | x_t, x_0) mean (use equation (4))\n",
    "        self.xt_coef = \n",
    "        self.x0_coef = \n",
    "        # ====\n",
    "\n",
    "    def get_x0(self, xt, eps, t):\n",
    "        # ====\n",
    "        # your code\n",
    "        # get x_0 (use equation (6))\n",
    "        # ====\n",
    "        return x0\n",
    "        \n",
    "    def get_mean_variance(self, xt, eps, t):\n",
    "        # ====\n",
    "        # your code\n",
    "        # get mean and variance of the distribution q(x_{t-1} | x_t, x_0) mean (use equations (4) and (5))\n",
    "\n",
    "        # ====\n",
    "        return mean, variance\n",
    "\n",
    "    def get_samples(self, xt, eps, t):\n",
    "        # read this code carefully\n",
    "        mean, variance = self.get_mean_variance(xt=xt, eps=eps, t=t)\n",
    "        noise = torch.randn_like(xt, device=xt.device)\n",
    "        \n",
    "        nonzero_mask = torch.ones_like(t)  # to not add any noise while predicting x0\n",
    "        nonzero_mask[t == 0] = 0\n",
    "        nonzero_mask = _extract_into_tensor(\n",
    "            nonzero_mask, torch.arange(nonzero_mask.shape[0]), xt.shape\n",
    "        )\n",
    "        nonzero_mask = nonzero_mask.to(xt.device)\n",
    "        sample = mean + nonzero_mask * variance.sqrt() * noise\n",
    "        return sample.float()\n",
    "\n",
    "\n",
    "def test_reverse_diffusion():\n",
    "    rdiff = ReverseDiffusion(num_timesteps=100)\n",
    "    SHAPE = [2, 20]\n",
    "    xt = torch.ones(SHAPE)\n",
    "    eps = torch.ones(SHAPE)\n",
    "    t = torch.ones((2,)).long() * 5\n",
    "    \n",
    "    x0 = rdiff.get_x0(xt=xt, eps=eps, t=t)\n",
    "    assert list(x0.shape) == SHAPE\n",
    "    assert np.allclose(x0.numpy(), np.ones(SHAPE) * 0.8260552)\n",
    "    \n",
    "    mean, variance = rdiff.get_mean_variance(xt=xt, eps=eps, t=t)\n",
    "    assert list(mean.shape) == SHAPE\n",
    "    assert list(variance.shape) == SHAPE\n",
    "    assert np.allclose(mean.numpy(), np.ones(SHAPE) * 0.9467155)\n",
    "    assert np.allclose(variance.numpy(), np.ones(SHAPE) * 0.007709955)\n",
    "\n",
    "    x = rdiff.get_samples(xt, eps, t)\n",
    "    assert list(x.shape) == SHAPE\n",
    "\n",
    "\n",
    "test_reverse_diffusion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "In this task we will use simple MLP model to parametrize distribution $p(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\boldsymbol{\\theta})$. It will be conditioned on the timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalMLP(nn.Module):\n",
    "    def __init__(self, input_dim: int, num_embeds: int, hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.x_proj = nn.Linear(input_dim, self.hidden_dim)\n",
    "        self.t_proj = nn.Embedding(num_embeds, self.hidden_dim)\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, 2 * self.hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(2 * self.hidden_dim, input_dim),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = self.x_proj(x)\n",
    "        t = self.t_proj(t.int())\n",
    "        x = x + t\n",
    "        x = F.gelu(x)\n",
    "        return self.backbone(x)\n",
    "\n",
    "\n",
    "def test_conditional_mlp():\n",
    "    SHAPE = [2, 20]\n",
    "    T = 100\n",
    "    x = torch.ones(SHAPE)\n",
    "    t = torch.ones((2,)).long() * 5\n",
    "    model = ConditionalMLP(input_dim=20, num_embeds=100)\n",
    "    output = model(x, t)\n",
    "    assert list(output.shape) == SHAPE\n",
    "    \n",
    "\n",
    "test_conditional_mlp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEZ__C82KlzL"
   },
   "source": [
    "Let return to the ELBO. The main part of it is:\n",
    "$$\n",
    "    \\mathcal{L}_t = KL \\bigl(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) || p(\\mathbf{x}_{t - 1} | \\mathbf{x}_t, \\boldsymbol{\\theta} )\\bigr)\n",
    "$$\n",
    "\n",
    "In Lecture 12 we have got that \n",
    "$$\n",
    "    \\mathcal{L}_t = \\mathbb{E}_{\\boldsymbol{\\epsilon}} \\left[ \\frac{\\beta_t^2}{2 \\tilde{\\beta_t} \\alpha_t (1 - \\bar{\\alpha}_t)} \\| \\boldsymbol{\\epsilon} - \\boldsymbol{\\epsilon}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t, t) \\|^2 \\right].\n",
    "$$\n",
    "\n",
    "In practice this loss is simplified. Particilarly, we will omit coefficient of the norm and we will sample index $t$ at each training step.\n",
    "\n",
    "Finally, we will train our model with the following objective:\n",
    "$$\n",
    "\\text{loss} = \\mathbb{E}_{\\mathbf{x}_0, \\boldsymbol{\\epsilon}, t}\\bigg[ \\|\\boldsymbol{\\epsilon} - \\boldsymbol{\\epsilon}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t, t)\\|^2\\bigg],\n",
    "$$\n",
    "where $\\mathbf{x}_t = \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\boldsymbol{\\epsilon}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following class implements two methods:\n",
    "- `train_loss` - to compute the loss at the training step;\n",
    "- `sample` - to sample from the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPM(nn.Module):\n",
    "    def __init__(self, num_timesteps: int, model: nn.Module):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_timesteps = num_timesteps\n",
    "        \n",
    "        self.forward_diffusion = ForwardDiffusion(num_timesteps=num_timesteps)\n",
    "        self.reverse_diffusion = ReverseDiffusion(num_timesteps=num_timesteps)\n",
    "        self.model = model\n",
    "        self.shape = None\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def sample(self, num_samples):\n",
    "        assert self.shape is not None\n",
    "        x = torch.randn((num_samples, *self.shape), device=self.device, dtype=torch.float32)\n",
    "        indices = list(range(self.num_timesteps))[::-1]\n",
    "\n",
    "        for i in tqdm(indices):\n",
    "            t = torch.tensor([i] * num_samples, device=x.device)\n",
    "            with torch.no_grad():\n",
    "                # ====\n",
    "                # your code\n",
    "                # 1) get epsilon from the model\n",
    "                # 2) sample from the reverse diffusion\n",
    "                \n",
    "                # ====\n",
    "        return x\n",
    "\n",
    "    def train_loss(self, x0):\n",
    "        if self.shape is None:\n",
    "            self.shape = list(x0.shape)[1:]\n",
    "        t = torch.randint(0, self.num_timesteps, size=(x0.size(0),), device=x0.device)\n",
    "        noise = torch.randn_like(x0)\n",
    "\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) get x_t\n",
    "        # 2) get epsilon from the model\n",
    "        \n",
    "        # ====\n",
    "        loss = F.mse_loss(eps, noise)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xw6vueDnTt7C"
   },
   "source": [
    "### Training\n",
    "\n",
    "Now we are ready to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    ddpm: DDPM,\n",
    "    dataloader,\n",
    "    lr: float,\n",
    "    weight_decay: float,\n",
    "    steps: int,\n",
    "    use_cuda: bool,\n",
    "    log_every: int = 500\n",
    "):\n",
    "\n",
    "    def _anneal_lr(step: int):\n",
    "        frac_done = step / steps\n",
    "        current_lr = lr * (1 - frac_done)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = current_lr\n",
    "            \n",
    "    if USE_CUDA:\n",
    "        ddpm = ddpm.cuda()\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        ddpm.model.parameters(), lr=lr, weight_decay=weight_decay\n",
    "    )\n",
    "    step = 0\n",
    "    curr_loss_gauss = 0.0\n",
    "    curr_count = 0\n",
    "    optimizer.zero_grad()\n",
    "    data_iter = iter(dataloader)\n",
    "    while step < steps:\n",
    "        try:\n",
    "            x = next(data_iter)\n",
    "        except StopIteration:\n",
    "            data_iter = iter(dataloader)\n",
    "            x = next(data_iter)\n",
    "            \n",
    "        if USE_CUDA:\n",
    "            x = x.cuda()\n",
    "            \n",
    "        loss = ddpm.train_loss(x)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        _anneal_lr(step)\n",
    "\n",
    "        curr_count += len(x)\n",
    "        curr_loss_gauss += loss.item() * len(x)\n",
    "\n",
    "        if (step + 1) % log_every == 0:\n",
    "            gloss = np.around(curr_loss_gauss / curr_count, 4)\n",
    "            print(f\"Step {(step + 1)}/{steps} Loss: {gloss}\")\n",
    "            curr_count = 0\n",
    "            curr_loss_gauss = 0.0\n",
    "\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 100\n",
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "BATCH_SIZE = \n",
    "LR = \n",
    "WEIGHT_DECAY = \n",
    "STEPS = \n",
    "# ====\n",
    "\n",
    "model = ConditionalMLP(input_dim=2, num_embeds=T)\n",
    "ddpm = DDPM(num_timesteps=T, model=model)\n",
    "\n",
    "dataloader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "train_model(\n",
    "    ddpm=ddpm, \n",
    "    dataloader=dataloader, \n",
    "    lr=LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    steps=STEPS,\n",
    "    use_cuda=USE_CUDA\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ijiAy6pUvkn"
   },
   "source": [
    "Now let's sample from our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1699716221687,
     "user": {
      "displayName": "Роман Исаченко",
      "userId": "08996523319375397632"
     },
     "user_tz": -180
    },
    "id": "wx1JhWdvfQZt",
    "outputId": "3a17bed6-b0f8-4dd9-bf0e-6bd769521624"
   },
   "outputs": [],
   "source": [
    "samples = ddpm.sample(num_samples=5000).cpu()\n",
    "\n",
    "visualize_2d_samples(samples, title=\"Samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RSpn0XJU_G9"
   },
   "source": [
    "Now let's see how denoising looks like (similarly to forward noising process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps=[0, 2, 4, 10, 50]\n",
    "\n",
    "x = torch.randn(train_data.shape[0], 2, requires_grad=False).to(ddpm.device)\n",
    "for i in range(ddpm.num_timesteps - 1, -1, -1):\n",
    "    t = torch.tensor(i, dtype=torch.long, requires_grad=False).expand(x.shape[0]).to(ddpm.device)\n",
    "    with torch.no_grad():\n",
    "        eps = ddpm.model(x, t)\n",
    "        x = ddpm.reverse_diffusion.get_samples(xt=x, eps=eps, t=t)\n",
    "    if i in reversed(timestamps):\n",
    "        x_ = x.cpu()\n",
    "        visualize_2d_samples(x_, title=f\"Samples from timestamp: {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXJnkzgiRGRo"
   },
   "source": [
    "## Task3: DDPM on MNIST (4pt)\n",
    "\n",
    "Let apply our diffusion model to the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = load_dataset(\"mnist\", flatten=False, binarize=False)\n",
    "\n",
    "visualize_images(train_data, \"MNIST samples\")\n",
    "\n",
    "DATA_MEAN = train_data.mean()\n",
    "DATA_STD = train_data.std()\n",
    "\n",
    "train_data = (train_data - DATA_MEAN) / DATA_STD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFhOvS0PPZoe"
   },
   "source": [
    "Let's take a look at the forward process for the MNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T = 1000\n",
    "\n",
    "fdiff = ForwardDiffusion(num_timesteps=T)\n",
    "\n",
    "timestamps=[0, 50, 100, 200, 300, 500, 600, 800, 999]\n",
    "\n",
    "plot_n_steps = len(timestamps)\n",
    "samples = []\n",
    "x0 = train_data[10:11]\n",
    "for i, t in enumerate(timestamps):\n",
    "    x = fdiff.get_samples(x0=torch.from_numpy(x0), t=torch.ones((x0.shape[0], 1)).long() * t)\n",
    "    samples.append(x.cpu().numpy())\n",
    "\n",
    "samples = np.concatenate(samples)\n",
    "samples = samples * DATA_STD + DATA_MEAN\n",
    "show_samples(samples, title=\"Noisy samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10tMXiU8P_6v"
   },
   "source": [
    "The model is written for you. We will use UNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import MyUNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you just have to train the model. All previous parts of the pipeline will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNvEMcANjpMk"
   },
   "outputs": [],
   "source": [
    "T = 1000\n",
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "BATCH_SIZE = \n",
    "LR = \n",
    "WEIGHT_DECAY = \n",
    "STEPS = \n",
    "# ====\n",
    "\n",
    "dataloader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model_mnist = MyUNet(n_steps=T)\n",
    "ddpm_mnist = DDPM(num_timesteps=T, model=model_mnist)\n",
    "\n",
    "train_model(\n",
    "    ddpm=ddpm_mnist, \n",
    "    dataloader=dataloader, \n",
    "    lr=LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    steps=STEPS,\n",
    "    use_cuda=USE_CUDA,\n",
    "    log_every=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4foGURhyRAaG"
   },
   "source": [
    "Let's draw samples from the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10167,
     "status": "ok",
     "timestamp": 1699721305095,
     "user": {
      "displayName": "Роман Исаченко",
      "userId": "08996523319375397632"
     },
     "user_tz": -180
    },
    "id": "j89yASABkOve",
    "outputId": "3acb8522-1f90-46f1-e13c-02d1ef4ba68f"
   },
   "outputs": [],
   "source": [
    "if USE_CUDA:\n",
    "    ddpm_mnist = ddpm_mnist.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    samples = ddpm_mnist.sample(num_samples=25).cpu().numpy()\n",
    "\n",
    "samples = samples * DATA_STD + DATA_MEAN\n",
    "\n",
    "show_samples(samples, title=\"Samples\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
